{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a06b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328167/3627197082.py:37: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_328167/3627197082.py:61: FutureWarning:\n",
      "\n",
      "DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "\n",
      "/home/aiubuntu01/anaconda3/envs/tf-gpu/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4320\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3759\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3075\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2251\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1593\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1265\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0937\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0820\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0691\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "#import yfinance as yf\n",
    "import os\n",
    "\n",
    "# Parameter\n",
    "#symbol = 'TSLA'\n",
    "pred_days = 100\n",
    "look_back = 60\n",
    "\n",
    "\n",
    "# 1. Daten abrufen\n",
    "folderPath_His = \"/Users/Shared/ai_work/Trainingdata/ml_data/yh_his/D1/\"\n",
    "folderPath_models = \"/Users/Shared/ai_work/Trainingdata/models/rnn/\"\n",
    "folderpath_results = \"/Users/Shared/ai_work/Trainingdata/ml_results/rnn/\"\n",
    "\n",
    "#\"/Users/workplacelivetv/Library/CloudStorage/GoogleDrive-robo01.rpa@gmail.com/My Drive/ml_data/yh_his/D1/\"\n",
    "#filepath = \"/Users/workplacelivetv/Library/CloudStorage/GoogleDrive-robo01.rpa@gmail.com/My Drive/ml_data/yh_his/D1/QBTS.csv\"\n",
    "symbol = '#PLTR'\n",
    "df = pd.read_csv (folderPath_His + symbol + \".csv\")\n",
    "#df = pd.read_csv (filepath)\n",
    "# Daten laden\n",
    "#df = yf.download(\"TSLA\", start=\"2018-01-01\", end=None)\n",
    "\n",
    "lastBars = 0\n",
    "n_tail = 200\n",
    "n_pred_days = 60\n",
    "n_time_steps = 60 # Neuronal Netzwerk\n",
    "sequence_length = 60\n",
    "n_epochs = 200 \n",
    "n_batch_size = 16\n",
    "df_his = df.tail(lastBars+1)\n",
    "df_his[\"date\"] = pd.to_datetime(df_his[\"date\"]) \n",
    "\n",
    "\n",
    "df = df[['date','open', 'high', 'low', 'close','volume']]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "data = df.copy()\n",
    "\n",
    "#data = df.copy()\n",
    "if n_tail > 0: data = data.tail(n_tail)\n",
    "if lastBars > 0: df = df[: len(data)-lastBars]\n",
    "#data = df[['close']].dropna()\n",
    "\n",
    "# 2. Technische Indikatoren berechnen\n",
    "data['SMA_20'] = data['close'].rolling(window=20).mean()\n",
    "change = data['close'].diff()\n",
    "gain = change.where(change > 0, 0).rolling(window=14).mean()\n",
    "loss = (-change.where(change < 0, 0)).rolling(window=14).mean()\n",
    "rs = gain / loss\n",
    "data['RSI'] = 100 - (100 / (1 + rs))\n",
    "ema12 = data['close'].ewm(span=12, adjust=False).mean()\n",
    "ema26 = data['close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = ema12 - ema26\n",
    "\n",
    "data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# 3. Features auswählen\n",
    "features = ['open', 'high', 'low', 'close', 'volume', 'SMA_20', 'RSI', 'MACD']\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[features])\n",
    "\n",
    "# 4. Sequenzen für LSTM vorbereiten\n",
    "X, y = [], []\n",
    "for i in range(look_back, len(scaled_data) - pred_days):\n",
    "    X.append(scaled_data[i - look_back:i])\n",
    "    y.append(scaled_data[i:i + pred_days, 3])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# 5. Modell erstellen\n",
    "model = Sequential([\n",
    "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(pred_days)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 6. Training\n",
    "model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# 7. Vorhersage für die nächsten 100 Handelstage\n",
    "last_seq = scaled_data[-look_back:]\n",
    "last_seq = np.expand_dims(last_seq, axis=0)\n",
    "pred_scaled = model.predict(last_seq)[0]\n",
    "\n",
    "# Rückskalieren\n",
    "scaler_close = MinMaxScaler()\n",
    "scaler_close.fit(data[['close']])\n",
    "pred_prices = scaler_close.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 8. Business-Day-Achse\n",
    "future_dates = pd.date_range(start=data.index[-1], periods=pred_days+1, freq='B')[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4faacc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage abgeschlossen. Plot gespeichert als tesla_forecast.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9. Plot erstellen\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data.index[-200:], y=data['close'][-200:], name='Historische Kurse'))\n",
    "fig.add_trace(go.Scatter(x=future_dates, y=pred_prices, name='Prognose (100 Tage)'))\n",
    "fig.update_layout(title='Tesla Aktienkurs Prognose mit LSTM', xaxis_title='Datum', yaxis_title='Preis (USD)')\n",
    "#fig.write_image('tesla_forecast.png')\n",
    "#fig.show()\n",
    "pred_prices\n",
    "print(\"Vorhersage abgeschlossen. Plot gespeichert als tesla_forecast.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf88a02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118.177246, 116.77951 , 130.88943 , 136.55763 , 114.50538 ,\n",
       "       140.48602 , 139.09131 , 127.72241 , 113.08691 , 122.33224 ,\n",
       "       128.2142  , 126.294716, 127.86634 , 133.94418 , 129.08917 ,\n",
       "       140.31357 , 152.50378 , 146.39069 , 135.5076  , 120.554504,\n",
       "       141.56844 , 127.832726, 145.49757 , 133.86577 , 131.79922 ,\n",
       "       149.50912 , 126.376335, 130.9237  , 155.69914 , 149.71056 ,\n",
       "       144.34622 , 153.13986 , 156.49513 , 145.29294 , 151.9641  ,\n",
       "       147.4032  , 156.47327 , 152.4198  , 169.2107  , 175.04431 ,\n",
       "       154.18175 , 148.6263  , 160.19121 , 174.88757 , 149.77174 ,\n",
       "       169.3794  , 160.68625 , 161.1202  , 160.00096 , 164.69562 ,\n",
       "       177.3905  , 155.13544 , 152.19456 , 165.19275 , 178.02548 ,\n",
       "       146.78297 , 146.79272 , 147.93788 , 169.95172 , 147.73685 ,\n",
       "       166.76526 , 171.79997 , 169.98303 , 128.02754 , 175.40968 ,\n",
       "       155.05798 , 163.95206 , 170.11963 , 156.9689  , 158.37032 ,\n",
       "       157.00156 , 158.7986  , 151.48518 , 171.7808  , 161.95775 ,\n",
       "       163.4048  , 145.47063 , 179.71661 , 162.98311 , 152.74654 ,\n",
       "       172.40959 , 158.75748 , 164.9805  , 166.1482  , 179.93515 ,\n",
       "       179.85738 , 173.81245 , 173.7634  , 172.51192 , 175.10286 ,\n",
       "       173.96696 , 157.46043 , 172.58664 , 202.76718 , 171.9175  ,\n",
       "       183.7037  , 177.97025 , 177.3542  , 188.55916 , 171.18188 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
