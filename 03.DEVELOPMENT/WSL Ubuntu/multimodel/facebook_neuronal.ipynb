{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol  = \"#PLTR\"\n",
    "import torch\n",
    "#print(torch.cuda.is_available())  # Sollte True ausgeben, wenn eine GPU erkannt wird\n",
    "#print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))  # Zeigt das verwendete GerÃ¤t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "WARNING - (py.warnings._showwarnmsg) - /var/folders/r7/mr4ntmy107d_924nk795zsqr0000gn/T/ipykernel_53696/1966211915.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_his[\"date\"] = pd.to_datetime(df_his[\"date\"])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /var/folders/r7/mr4ntmy107d_924nk795zsqr0000gn/T/ipykernel_53696/1966211915.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_his[\"date\"] = pd.to_datetime(df_his[\"date\"])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "folderpath_models =\"/Users/Shared/ai_work/Trainingdata/models/neuralprophet/modelfiles/\"\n",
    "folderpath_traininglogs =\"/Users/Shared/ai_work/Trainingdata/models/neuralprophet/traininglogs/\"\n",
    "folderpath_charts = \"/Users/Shared/ai_work/Trainingdata/models/neuralprophet/charts/\"\n",
    "folderpath_historie =\"/Users/Shared/ai_work/Trainingdata/ml_data/yh_his/D1/\"\n",
    "folderpath_results = \"/Users/Shared/ai_work/Trainingdata/ml_results/fb_nrp/\"\n",
    "folderpath_analyse = \"/Users/Shared/ai_work/Trainingdata/ml_analyse/fb_nrp/\"\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŸ¢ Step 1: Download Tesla stock data\n",
    "#ticker = \"TSLA\"\n",
    "\n",
    "filepath_model = folderpath_models+symbol+\".pth\"\n",
    "#filepath_model = folderpath_models+symbol+\".np\"\n",
    "\n",
    "#df = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
    "df = pd.read_csv (folderpath_historie+symbol+\".csv\")\n",
    "n_pred_days = 100\n",
    "n_lags_days =  50\n",
    "n_learning_rate  = 0.01\n",
    "n_epochs = 400\n",
    "n_batch_size = 16\n",
    "\n",
    "isretain = 1\n",
    "check_file = 0 \n",
    "\n",
    "lastBars = 0\n",
    "n_tail = 500\n",
    "df_his = df.tail(lastBars+1)\n",
    "df_his[\"date\"] = pd.to_datetime(df_his[\"date\"]) \n",
    "df = df[:len(df) - lastBars]\n",
    "\n",
    "# ðŸŸ¢ Step 2: Preprocess data for NeuralProphet\n",
    "df.reset_index(inplace=True)  # Reset index to get 'Date' column\n",
    "df = df.rename(columns={\"date\": \"ds\", \"close\": \"y\"})  # Rename columns\n",
    "df[\"ds\"] = pd.to_datetime(df[\"ds\"])  # Ensure 'ds' is datetime\n",
    "df = df[[\"ds\", \"y\"]]  # Keep only required columns\n",
    "if n_tail > 0 : df = df.tail (n_tail)\n",
    "# ðŸŸ¢ Step 3: Initialize and fit NeuralProphet model\n",
    "#model = NeuralProphet(daily_seasonality=True)\n",
    "\n",
    "# PrÃ¼fe, ob CUDA oder MPS verfÃ¼gbar ist\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "#model = NeuralProphet(trainer_kwargs={\"accelerator\": device})\n",
    "\n",
    "\n",
    "if os.path.exists(filepath_model):check_file = 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCheck (symbol, n_epochs, n_batch_size, n_tail, n_learning_rate,  \n",
    "                d_seasonality, w_seasonality,y_seasonality,  df,  df_log,  model_no ):\n",
    "     \n",
    "     df = df.tail(n_tail)\n",
    "    \n",
    "     model = NeuralProphet(daily_seasonality=d_seasonality, weekly_seasonality=w_seasonality, yearly_seasonality=y_seasonality , seasonality_mode=\"additive\", \n",
    "                      learning_rate=n_learning_rate, \n",
    "                      epochs = n_epochs, batch_size = n_batch_size\n",
    "                      )\n",
    "     \n",
    "     metrics = model.fit(df, freq=\"B\")\n",
    "     loss = metrics['Loss'].values[-1]\n",
    "     \n",
    "     \n",
    "     model_file_name = symbol +str(model_no)+\".pth\"\n",
    "     filepath_model = folderpath_models + model_file_name\n",
    "\n",
    "     torch.save(model, filepath_model)\n",
    "     now = datetime.now()\n",
    "     \n",
    "\n",
    "     new_row = pd.DataFrame({'n_epochs': [n_epochs], 'n_batch_size': [n_batch_size], 'n_tail': [n_tail] , 'loss': [loss], 'model':[model_file_name], 'created':[now], \n",
    "                             'learning_rate':[n_learning_rate], 'daily_seasonality': [d_seasonality], 'weekly_seasonality':[w_seasonality],  'yearly_seasonality':[y_seasonality]})\n",
    "     df_log = pd.concat([df_log, new_row], ignore_index=True)\n",
    "     return df_log\n",
    "     \n",
    "     #training_check= f\"Learning Rate {n_learning_rate} / epochs: {n_epochs} / n_batch_size: {n_batch_size} / n_tail:  {n_tail}: Loss = {metrics['Loss'].values[-1]}\"\n",
    "#{}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def createResult (symbol):\n",
    "     #folderpath_results = \"D:/OneDrive/AI Workspace/results/nrp_results/\"\n",
    "     csvfileresult  = folderpath_results+symbol + \".csv\"\n",
    "     with open(csvfileresult , 'w', newline='') as csvfilerow:\n",
    "                           fieldnames = ['Symbol','Type','Date','Close','Source','Change']\n",
    "                           writer = csv.DictWriter(csvfilerow, fieldnames=fieldnames)\n",
    "                           writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseForecast (forecast, df):\n",
    "    df_change = forecast\n",
    "    df_change [\"change\"] = round ( df_change['yhat1'].pct_change() , 3) \n",
    "    \n",
    "    forecast[\"mean\"] = forecast[\"yhat1\"].mean()\n",
    "    #forecast[\"mean\"] = forecast[\"yhat1\"].mean()\n",
    "\n",
    "    lastclose = df[\"y\"].iloc[-1]\n",
    "    lastdate = df[\"ds\"].iloc[-1]\n",
    "    lasttrend_close = forecast[\"trend\"].iloc[-1]\n",
    "    lasttrend_date  = forecast[\"ds\"].iloc[-1]\n",
    "    firsttrend_close = forecast[\"trend\"].iloc[1:2]\n",
    "    firsttrend_date  = forecast[\"ds\"].iloc[1:2]\n",
    "    lasttrend_close = forecast[\"trend\"].iloc[-1]\n",
    "    lasttrend_date  = forecast[\"ds\"].iloc[-1]\n",
    "\n",
    "    trend_change = (lasttrend_close - firsttrend_close)/firsttrend_close\n",
    "    endclose = round( (lastclose + lastclose *trend_change),2)\n",
    "    trend_change\n",
    "    lasttrend_close\n",
    "\n",
    "    # Create a list of dates (ds) and corresponding values (y)\n",
    "    df_trend  = {\n",
    "      'ds': [lastdate, lasttrend_date],\n",
    "      'trend_close': [float(lastclose), float(endclose)]\n",
    "    }\n",
    "    df_trend = pd.DataFrame(df_trend)\n",
    "    columns = ['cal']\n",
    "\n",
    "   # Create an empty DataFrame\n",
    "    df_cal = pd.DataFrame(columns=columns)\n",
    "    i= 0 \n",
    "    fc = lastclose\n",
    "    #df_change['cal'] = 0\n",
    "    #print (df_change)\n",
    "\n",
    "    for s in df_change.values: \n",
    "        i= i +1\n",
    "       \n",
    "        #if i == 1: fc = lastclose\n",
    "        if i > 1 : \n",
    "           change =  s[6]\n",
    "           \n",
    "           fc = fc+ fc* change\n",
    "        \n",
    "      \n",
    "        #df_change['cal'][i] = fc\n",
    "        new_row = pd.DataFrame({'cal': [fc]})\n",
    "        df_cal = pd.concat([df_cal, new_row], ignore_index=True)\n",
    "        \n",
    "        \n",
    "   # Convert the dictionary into a pandas DataFrame\n",
    "    df_change ['cal']=  df_cal ['cal']\n",
    "    filepath_result =folderpath_analyse+symbol+\".csv\"\n",
    "    df_change.to_csv (filepath_result)\n",
    "    \n",
    "    return df_trend, df_change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResult (symbol, df,df_his, forecast, df_trend , df_change, model_file, isbestmodel):\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df = df.tail(200)\n",
    "    #plt.plot(df_trend[\"ds\"], df_trend[\"trend_close\"], label=\"Historical Data\", color=\"pink\")\n",
    "    plt.plot(df_trend[\"ds\"], df_trend[\"trend_close\"], label=\"Forecast\", color=\"red\",  linestyle='--') \n",
    "    plt.plot(df_change[\"ds\"], df_change[\"cal\"], label=\"CAL FC\", color=\"green\",  linestyle='-') \n",
    "    plt.plot(df[\"ds\"], df[\"y\"], label=\"Historical Data\", color=\"blue\")\n",
    "    plt.plot(df_his[\"date\"], df_his[\"close\"], label=\"IS HIS\", color=\"Magenta\")\n",
    "\n",
    "    # Plot predicted stock prices\n",
    "    plt.plot(forecast[\"ds\"], forecast[\"mean\"], label=\"mean\", color=\"black\")\n",
    "    plt.plot(forecast[\"ds\"], forecast[\"yhat1\"], label=\"Predicted Data\", color=\"red\")\n",
    "    plt.plot(forecast[\"ds\"], forecast[\"trend\"], label=\"Predicted trend\", color=\"green\")\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Stock Price (USD)\")\n",
    "    plt.title(f\"{symbol} Stock Price Prediction (Next {n_pred_days} Days)  with model  {model_file} {isbestmodel} \")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    # Save to file\n",
    "    import os\n",
    "\n",
    "    folder_path = folderpath_charts + symbol+\"/\"\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder_path): os.makedirs(folder_path)\n",
    "   \n",
    "\n",
    "    plt.savefig( folder_path + model_file+isbestmodel+\"_chart.png\", dpi=300, bbox_inches='tight')\n",
    "   # Show plot\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelFile (df_log):\n",
    "    \n",
    "    \n",
    "    df_sorted_desc = df_log.sort_values(by='loss', ascending=True)\n",
    "    \n",
    "    first_row = df_sorted_desc.iloc[0]\n",
    "    \n",
    "    #model_file = first_row['model'][0]\n",
    "    model_file = first_row[\"model\"]\n",
    "    \n",
    "    return model_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 20)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:20\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel = torch.load(filepath_model, map_location=torch.device('cpu'))\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def getForecastByModelFile (symbol, model_file, df , df_his , isbestmodel):\n",
    "   \n",
    "  filepath_model = folderpath_models + str(model_file)\n",
    "  if os.path.exists(filepath_model):\n",
    "   # Safely load model depending on available device. If CUDA is unavailable\n",
    "   # the model may have been saved with CUDA tensors â€” map to CPU in that case.\n",
    "    try:\n",
    "     if torch.cuda.is_available():\n",
    "       model = torch.load(filepath_model, weights_only=False)\n",
    "     else:\n",
    "       # Prefer mapping to the local device; fallback to CPU on failure.\n",
    "       try:\n",
    "         model = torch.load(filepath_model, map_location=torch.device('cpu'), weights_only=False)\n",
    "       except TypeError:\n",
    "         # Older torch versions may not support weights_only kwarg together with map_location\n",
    "         model = torch.load(filepath_model, map_location=torch.device('cpu'))\n",
    "    except RuntimeError as e:\n",
    "      # Common case: model saved on CUDA but running without CUDA.\n",
    "      print(\"Warning: model load fell back to CPU due to runtime error:\\n\", e)\n",
    "   model = torch.load(filepath_model, map_location=torch.device('cpu'))\n",
    "   future = model.make_future_dataframe(df, periods=n_pred_days )\n",
    "   forecast = model.predict(future)\n",
    "   df_trend , df_change = analyseForecast (forecast, df)\n",
    "\n",
    "  plotResult (symbol, df,df_his, forecast, df_trend, df_change,  model_file , isbestmodel)\n",
    " else: \n",
    "     print (\"Load model failed: \", filepath_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file:  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     39\u001b[39m   best_model_file = getBestModelFile (df_log)\n\u001b[32m     46\u001b[39m df_log = df_log.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mgetForecastByModelFile\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_his\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTOP\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m#Display other models\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df_log.values:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mgetForecastByModelFile\u001b[39m\u001b[34m(symbol, model_file, df, df_his, isbestmodel)\u001b[39m\n\u001b[32m      3\u001b[39m filepath_model = folderpath_models + \u001b[38;5;28mstr\u001b[39m(model_file)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(filepath_model):\n\u001b[32m      5\u001b[39m   \u001b[38;5;66;03m#model = torch.load(filepath_model)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m   model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m   future = model.make_future_dataframe(df, periods=n_pred_days )\n\u001b[32m      9\u001b[39m   forecast = model.predict(future)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:1525\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1530\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1533\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:2078\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2077\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2078\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:2044\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2040\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   2041\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   2043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2046\u001b[39m     storage._fake_device = location\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:698\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    680\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    696\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:636\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    634\u001b[39m     backend_name = torch._C._get_privateuse1_backend_name()\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/multimodel/lib/python3.11/site-packages/torch/serialization.py:605\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    603\u001b[39m     device_index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mis_available\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    606\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    607\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.is_available() is False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    608\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you are running on a CPU-only machine, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto map your storages to the CPU.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    611\u001b[39m     )\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mdevice_count\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    613\u001b[39m     device_count = device_module.device_count()\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#df_log = {'n_epochs', 'n_batch_size','n_tail', 'loss'}\n",
    "\n",
    "model = NeuralProphet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True , seasonality_mode=\"additive\", \n",
    "                      learning_rate=n_learning_rate, \n",
    "                      epochs = n_epochs, batch_size = n_batch_size\n",
    "                      )\n",
    "# Define column names\n",
    "columns = ['n_epochs', 'n_batch_size', 'n_tail','loss','model','learning_rate','daily_seasonality', 'weekly_seasonality', 'yearly_seasonality', 'created']\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df_log = pd.DataFrame(columns=columns)\n",
    "\n",
    "filepath_traninglog = folderpath_traininglogs+symbol +\".csv\"\n",
    "\n",
    "checkmodel_exist = 0 \n",
    "model_file =\"\"\n",
    "\n",
    "best_model_file = model_file\n",
    "\n",
    "if os.path.exists(filepath_traninglog):\n",
    "    df_log = pd.read_csv (filepath_traninglog)\n",
    "  \n",
    "    best_model_file = getBestModelFile (df_log)\n",
    "    print (\"Model file: \", model_file)\n",
    "    #df_sorted_desc.tail(1)\n",
    "    #model_file = \"#NVDA5.pth\"\n",
    "\n",
    "#Retrain models\n",
    "if best_model_file ==\"\":\n",
    "  df_log = trainCheck (symbol, 200,16,200, 0.001, False, True, True, df, df_log, 1)\n",
    "  df_log = trainCheck (symbol, 200,16,400,0.001 ,False, True, True, df, df_log,2)\n",
    "  df_log = trainCheck (symbol, 200,8,200,0.002,False,  True, True, df, df_log,3)\n",
    "  df_log = trainCheck (symbol, 400,8,400,0.005, False, True, True, df, df_log,4)\n",
    "  df_log = trainCheck (symbol, 600,16,400,0.001, False, True, True, df, df_log,5)\n",
    "  #df_log = df_log.sort_values(by='loss', ascending=True)\n",
    "  df_log.to_csv (folderpath_traininglogs+symbol +\".csv\")\n",
    "  df_log = pd.read_csv (filepath_traninglog)\n",
    " \n",
    "  best_model_file = getBestModelFile (df_log)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "df_log = df_log.sort_values(by='loss', ascending=True)\n",
    "getForecastByModelFile (symbol, best_model_file, df , df_his, \"TOP\" )\n",
    "\n",
    "#Display other models\n",
    "for row in df_log.values:\n",
    "  isbestmodel =\"\"\n",
    "  model_file = row[5]\n",
    "  if model_file != best_model_file: getForecastByModelFile (symbol, model_file, df , df_his, \"\" )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
